{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8367fc6-5d33-4146-9240-3aed28316e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from utility import review_to_words\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#def data_load(file = 'train_E6oV3lV.csv', test_split: float = 0.1, random_seed: int = 3):\n",
    "df = pd.read_csv('train_E6oV3lV.csv')\n",
    "df = df.drop(['id'], axis=1)\n",
    "#X = df['tweet']\n",
    "#y = df['label']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "#train_X, train_y = shuffle(X_train, y_train)\n",
    "#test_X, test_y = shuffle(X_test, y_test)\n",
    "#train_X = train_X.apply(lambda x:review_to_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1189721-beb6-461e-9c69-730c9d3d7c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0   @user when a father is dysfunctional and is s...\n",
       "1      0  @user @user thanks for #lyft credit i can't us...\n",
       "2      0                                bihday your majesty\n",
       "3      0  #model   i love u take with u all the time in ..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e7221ac8-bd4d-4513-bb91-dfa7cdca11dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "13d6ab0a-9659-4baf-871c-f0ea0e1dde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the train and test tweet\n",
    "#print(train_X[1])\n",
    "#print(train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f185ac-39dd-48b3-aeec-355796cc0aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e5cc17c-a67f-4866-bb1e-25083bd68b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8d4b651-b5f4-49f0-94e5-393122c58847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2064\\2137687332.py:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                              tweet  \\\n",
      "0          0   @user when a father is dysfunctional and is s...   \n",
      "1          0  @user @user thanks for #lyft credit i can't us...   \n",
      "2          0                                bihday your majesty   \n",
      "3          0  #model   i love u take with u all the time in ...   \n",
      "4          0             factsguide: society now    #motivation   \n",
      "...      ...                                                ...   \n",
      "31957      0  ate @user isz that youuu?ðððððð...   \n",
      "31958      0    to see nina turner on the airwaves trying to...   \n",
      "31959      0  listening to sad songs on a monday morning otw...   \n",
      "31960      1  @user #sikh #temple vandalised in in #calgary,...   \n",
      "31961      0                   thank you @user for you follow     \n",
      "\n",
      "                                                     new  \n",
      "0      [user, father, dysfunct, selfish, drag, kid, d...  \n",
      "1      [user, user, thank, lyft, credit, use, caus, o...  \n",
      "2                                      [bihday, majesti]  \n",
      "3                    [model, love, u, take, u, time, ur]  \n",
      "4                            [factsguid, societi, motiv]  \n",
      "...                                                  ...  \n",
      "31957                            [ate, user, isz, youuu]  \n",
      "31958  [see, nina, turner, airwav, tri, wrap, mantl, ...  \n",
      "31959  [listen, sad, song, monday, morn, otw, work, sad]  \n",
      "31960  [user, sikh, templ, vandalis, calgari, wso, co...  \n",
      "31961                              [thank, user, follow]  \n",
      "\n",
      "[31962 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#try apply for one of the tweets\n",
    "df['new'] = df['tweet'].apply(review_to_words)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b303e41a-e887-45bb-bf40-ffe2c158627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [user, father, dysfunct, selfish, drag, kid, d...\n",
       "1        [user, user, thank, lyft, credit, use, caus, o...\n",
       "2                                        [bihday, majesti]\n",
       "3                      [model, love, u, take, u, time, ur]\n",
       "4                              [factsguid, societi, motiv]\n",
       "                               ...                        \n",
       "31957                              [ate, user, isz, youuu]\n",
       "31958    [see, nina, turner, airwav, tri, wrap, mantl, ...\n",
       "31959    [listen, sad, song, monday, morn, otw, work, sad]\n",
       "31960    [user, sikh, templ, vandalis, calgari, wso, co...\n",
       "31961                                [thank, user, follow]\n",
       "Name: new, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06e61c11-870c-48f9-8f65-d848e0a565f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['new'].values\n",
    "Y= df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96665df2-8bc1-44e7-a293-a5f80cd869a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b65e9b1-9395-4c46-9aa8-00dcaaa81402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X, Y,stratify=Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e26425c8-2293-4b45-a024-7968b435a35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14695    just enjoying the day. #freespirit #hippie #hi...\n",
       "18188      is defunding aboion and sending you to the #...\n",
       "13579       coffe go to work ðð   #miercolesbonitos \n",
       "2066     salute to all fathers active in they kids live...\n",
       "2802     confirmation teacher? the youth director is in...\n",
       "                               ...                        \n",
       "20341    wow. i really ate the last of the fried chicke...\n",
       "11593    what makes your little one   today? ad  #mom #...\n",
       "20594    #beachday   gorilla simulator: you need to do ...\n",
       "21973    set of 4 moroc... gbp 19.00 get here:  #shop #...\n",
       "21097    dang i clicked on this girls selfies cause she...\n",
       "Name: tweet, Length: 25569, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5c14362-ada4-4eeb-9f92-dd961bcab3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11853     @user have had setup #bbc #iplayer to watch n...\n",
       "24517    all tickets have been delivered, lets get read...\n",
       "8732     @user # in other words creditors do not want  ...\n",
       "12285     @user .@user kill an #animal &amp; market it ...\n",
       "3057             and destructive socialists #maddow @user \n",
       "                               ...                        \n",
       "24964    #interested in what i do? lets #chat and have ...\n",
       "7256       @user saturday shooting @user   #beretta @user \n",
       "14156    every monday, i tell myself that i will give t...\n",
       "3236     my \"happy things place\" âºï¸ all my scuba st...\n",
       "13962    shout out to @user 4 following me! can't wait ...\n",
       "Name: tweet, Length: 6393, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d19dddc-0b6f-4cca-ac0e-af30b9bd1b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "181333ed-82b1-457a-95b5-9d7c6fa4fe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d7f61db-c689-43f4-9910-6ac2b1164f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cache_data = dict(words_train=train_X, words_test=test_X,\n",
    "                              #labels_train=train_y, labels_test=test_y)\n",
    "#with open('preprocessed.pkl', \"wb\") as f:\n",
    "    #pickle.dump(cache_data, f)\n",
    "\n",
    "#print(\"Wrote preprocessed data to cache file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a61eee7b-0376-4e08-8b78-c3396db19d7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (864916974.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[99], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    working_sentence[word_index] = word_dict[word]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#def convert_and_pad(word_dict, sentence, pad=256):\n",
    "    #NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    #INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    #working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    #for word_index, word in enumerate(sentence[:pad]):\n",
    "        #if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        #else:\n",
    "            #working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    #return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "#def convert_and_pad_data(word_dict, data, pad=256):\n",
    "    #result = []\n",
    "    #lengths = []\n",
    "    \n",
    "    #for sentence in data:\n",
    "        #converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        #result.append(converted)\n",
    "        #lengths.append(leng)\n",
    "        \n",
    "    #return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e97431bb-e875-48a0-b2a0-1050a33d1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
    "#test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27a85129-772d-4a67-8901-6e37dcb98bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid entries\n",
    "train_X = [doc for doc in X_train if isinstance(doc, (list, str))]\n",
    "test_X = [doc for doc in X_test if isinstance(doc, (list, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c980729-7628-45d8-aed7-d578d189b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_new = [\" \".join(doc) if isinstance(doc, list) else doc for doc in train_X]\n",
    "test_X_new = [\" \".join(doc) if isinstance(doc, list) else doc for doc in test_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dd5f6-30d8-4c59-a8bf-90f618c0572f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b6bff3c-672f-4406-a0a4-720c7ffc76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of words back into strings\n",
    "#train_X = [\" \".join(doc) for doc in X_train]\n",
    "#test_X = [\" \".join(doc) for doc in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f2d46143-48e1-497e-ac89-5e79ea1a499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 25569\n",
      "Number of testing samples: 6393\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples:\", len(train_X_new))\n",
    "print(\"Number of testing samples:\", len(test_X_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ddf2-9216-43ae-b958-aba2ee03269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction or converting the features into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1272e84c-36ab-495d-8251-041fed8cc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe5e6af4-4a13-41e9-972b-ad6d6d790884",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76aa2d14-dbb1-4ce9-b25e-88551d5a42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fit the vectorizer on training data and transform train_X\n",
    "train_X_tfidf = tfidf_vectorizer.fit_transform(train_X_new)\n",
    "\n",
    "# Step 3: Transform test_X using the same vectorizer\n",
    "test_X_tfidf = tfidf_vectorizer.transform(test_X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fe981a4e-c115-4bdd-897d-2aa6c0fac952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569, 36035)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b01cff4-63ea-44e8-a56d-58856bf6af8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25569x36035 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 293491 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9f8fd-26cd-459f-941a-dd937113b964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
